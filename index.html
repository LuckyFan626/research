<html>
  <head>
    <meta charset="UTF-8">
    <title>Audio samples related to Tacotron, an end-to-end speech synthesis system by Google.</title>
    <link rel="stylesheet" type="text/css" href="stylesheet.css"/>
    <link rel="shortcut icon" href="images/taco.png">
  </head>
  <body>
    <h1>
      <img src="images/taco.png"/><img src="images/tron.png"/><br/>
      Tacotron (/täkōˌträn/): An end-to-end speech synthesis system by Google
    </h1>
    <h2>Publications</h2>
    <article>
      <header>
	<span class="paper_date">(March 2017)</span>
	<span class="paper_title">Tacotron: Towards End-to-End Speech Synthesis</span>
	<ul>
	  <li><a href="https://arxiv.org/abs/1703.10135">paper</a></li>
	  <li><a href="publications/tacotron/index.html">audio samples</a></li>
	</ul>
      </header>
    </article>

    <article>
      <header>
	<span class="paper_date">(November 2017)</span>
	<span class="paper_title">Uncovering Latent Style Factors for Expressive Speech Synthesis</span>
	<ul>
	  <li><a href="https://arxiv.org/abs/1711.00520">paper</a></li>
	  <li><a href="publications/uncovering_latent_style_factors_for_expressive_speech_synthesis/index.html">audio samples</a></li>
	</ul>
      </header>
    </article>

    <article>
      <header>
	<span class="paper_date">(December 2017)</span>
	<span class="paper_title">Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions</span>
	<ul>
	  <li><a href="https://research.googleblog.com/2017/12/tacotron-2-generating-human-like-speech.html">blog post</a></li>
	  <li><a href="https://arxiv.org/abs/1712.05884">paper</a></li>
	  <li><a href="publications/tacotron2/index.html">audio samples</a></li>
	</ul>
      </header>
    </article>

    <article>
      <header>
	<span class="paper_date">(March 2018)</span>
	<span class="paper_title">Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron</span>
	<ul>
	  <li><a href="https://research.googleblog.com/2018/03/expressive-speech-synthesis-with.html">blog post</a></li>
	  <li><a href="https://arxiv.org/abs/1803.09047">paper</a></li>
	  <li><a href="publications/end_to_end_prosody_transfer/index.html">audio samples</a></li>
	  <li><a href="https://vimeo.com/287802601">talk</a></li>
	</ul>
      </header>
    </article>

    <article>
      <header>
	<span class="paper_date">(March 2018)</span>
	<span class="paper_title">Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis</span>
        <ul>
	  <li><a href="https://research.googleblog.com/2018/03/expressive-speech-synthesis-with.html">blog post</a></li>
	  <li><a href="https://arxiv.org/abs/1803.09017">paper</a></li>
	  <li><a href="publications/global_style_tokens/index.html">audio samples</a></li>
	</ul>
      </header>
    </article>

    <article>
      <header>
        <span class="paper_date">(June 2018)</span>
        <span class="paper_title">Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis</span>
        <ul>
          <li><a href="https://arxiv.org/abs/1806.04558">paper</a></li>
          <li><a href="publications/speaker_adaptation/index.html">audio samples</a></li>
        </ul>
      </header>
    </article>
  </body>
</html>
